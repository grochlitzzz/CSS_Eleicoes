{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bb75a8",
   "metadata": {},
   "source": [
    "# Computational Social Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63089229",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65be58c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m discovery\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\api.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, registry, ConfigValidationError\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normal_init, uniform_init, glorot_uniform_init, zero_init\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_normal_init\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalCrossentropy, L2Distance, CosineDistance\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\initializers.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, cast\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatsXd, Shape\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\backends\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextvars\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ContextVar\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcupy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CupyOps, has_cupy\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\backends\\ops.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatsXd, Ints1d, Ints2d, Ints3d, Ints4d, IntsXd, _Floats\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceTypes, Generator, Padded, Batchable, SizedGenerator\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_array_module, is_xp_array, to_numpy\n\u001b[0;32m     16\u001b[0m ArrayT \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrayT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mArrayXd)\n\u001b[0;32m     17\u001b[0m FloatsT \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFloatsT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m_Floats)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\util.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m     torch_version \u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdlpack\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     has_tensorflow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:37\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatible\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v2\\__init__.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\compat\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatible\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\compat\\v2\\__init__.py:329\u001b[0m\n\u001b[0;32m    327\u001b[0m _current_module \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 329\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m    330\u001b[0m   _current_module\u001b[38;5;241m.\u001b[39m__path__ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    331\u001b[0m       [_module_util\u001b[38;5;241m.\u001b[39mget_parent_dir(summary)] \u001b[38;5;241m+\u001b[39m _current_module\u001b[38;5;241m.\u001b[39m__path__)\n\u001b[0;32m    332\u001b[0m   \u001b[38;5;28msetattr\u001b[39m(_current_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m, summary)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# If the V1 summary API is accessible, load and re-export it here.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\v1.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _audio_summary\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_scalar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _custom_scalar_summary\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _histogram_summary\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _image_summary\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpr_curve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary \u001b[38;5;28;01mas\u001b[39;00m _pr_curve_summary\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary.py:35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary_v2\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Export V3 versions.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m histogram \u001b[38;5;241m=\u001b[39m summary_v2\u001b[38;5;241m.\u001b[39mhistogram\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazy_tensor_creator\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_util\n\u001b[0;32m     38\u001b[0m DEFAULT_BUCKET_COUNT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhistogram_pb\u001b[39m(tag, data, buckets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\util\\tensor_util.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow_stub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes, compat, tensor_shape\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mExtractBitsFromFloat16\u001b[39m(x):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint16)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_graph_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m as_dtype  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DType  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Library of dtypes (Tensor element types).\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     22\u001b[0m _np_bfloat16 \u001b[38;5;241m=\u001b[39m pywrap_tensorflow\u001b[38;5;241m.\u001b[39mTF_bfloat16_type()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\pywrap_tensorflow.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstruct\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfile\n\u001b[0;32m     25\u001b[0m TFE_DEVICE_PLACEMENT_WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     26\u001b[0m TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfile\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m     S3_ENABLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     FSSPEC_ENABLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fsspec\\__init__.py:65\u001b[0m\n\u001b[0;32m     59\u001b[0m                 err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load filesystem from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m                 register_implementation(\n\u001b[0;32m     61\u001b[0m                     spec\u001b[38;5;241m.\u001b[39mname, spec\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m), errtxt\u001b[38;5;241m=\u001b[39merr_msg\n\u001b[0;32m     62\u001b[0m                 )\n\u001b[1;32m---> 65\u001b[0m \u001b[43mprocess_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\fsspec\\__init__.py:50\u001b[0m, in \u001b[0;36mprocess_entries\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         eps \u001b[38;5;241m=\u001b[39m \u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# importlib-metadata < 0.8\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\importlib\\metadata.py:580\u001b[0m, in \u001b[0;36mentry_points\u001b[1;34m()\u001b[0m\n\u001b[0;32m    577\u001b[0m eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m    578\u001b[0m     dist\u001b[38;5;241m.\u001b[39mentry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m distributions())\n\u001b[0;32m    579\u001b[0m by_group \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 580\u001b[0m ordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m grouped \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mgroupby(ordered, by_group)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    583\u001b[0m     group: \u001b[38;5;28mtuple\u001b[39m(eps)\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group, eps \u001b[38;5;129;01min\u001b[39;00m grouped\n\u001b[0;32m    585\u001b[0m     }\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\importlib\\metadata.py:578\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentry_points\u001b[39m():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;124;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    :return: EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m--> 578\u001b[0m         \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m distributions())\n\u001b[0;32m    579\u001b[0m     by_group \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    580\u001b[0m     ordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(eps, key\u001b[38;5;241m=\u001b[39mby_group)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\setuptools\\_vendor\\importlib_metadata\\__init__.py:609\u001b[0m, in \u001b[0;36mDistribution.entry_points\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints\u001b[38;5;241m.\u001b[39m_from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentry_points.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\setuptools\\_vendor\\importlib_metadata\\__init__.py:917\u001b[0m, in \u001b[0;36mPathDistribution.read_text\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[0;32m    916\u001b[0m     ):\n\u001b[1;32m--> 917\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pathlib.py:1267\u001b[0m, in \u001b[0;36mPath.read_text\u001b[1;34m(self, encoding, errors)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03mOpen the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keyring\n",
    "import tweepy\n",
    "import datetime\n",
    "import time\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from googleapiclient import discovery\n",
    "from pyUFbr.baseuf import ufbr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1692b8",
   "metadata": {},
   "source": [
    "## Twitter API Access\n",
    "### Secure access with keyring library (not crucial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f837bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKey = \"otyOoFqTqYG2S5BExsnu4Mu9E\"\n",
    "APIKeySecret = \"4OXZSaK1SVeXEvHDy8JPsKm3yXOONwKNDPCwv1uyuhmljEBVoO\"\n",
    "BearerToken = \"AAAAAAAAAAAAAAAAAAAAACAnkAEAAAAAkxcXL6XD2TRW9FeYBOiZcxsASkU%3DaVO7yShAWO1KwrZossbSR4OZGyrmWDap4jlnLcNdHSL2IKgKzX\"\n",
    "TOKEN = \"1598267162338131968-HesHQlS0MjKKutBMVE6tv0GMGf9ztU\"\n",
    "TOKEN_SECRET = \"BTvRyVD7Wv1gHbIr3EbZlO1tZcOnooazhs1C9GZiE9lIq\"\n",
    "\n",
    "## Accessing Twitter API\n",
    "\n",
    "auth = tweepy.OAuthHandler(APIKey, APIKeySecret)\n",
    "auth.set_access_token(TOKEN, TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "client = tweepy.Client(bearer_token=BearerToken,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356cdb8",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "### Perspective API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37056e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Perspective = \"AIzaSyCJWFvEfdRaS2-h2CYAP4Pn7AaTAOrCfo4\"\n",
    "clientPerspective = discovery.build(\n",
    "    \"commentanalyzer\",\n",
    "    \"vlaphal\",\n",
    "    developerKey=API_Perspective,\n",
    "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "    static_discovery=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267db7f",
   "metadata": {},
   "source": [
    "## Getting Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aad2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "query = '(#Eleicoes2022 OR #Eleicao2022 OR #Bolsonaro22 OR #LulaPresidente13 OR #lulapresidente2022 OR #LulaPresidente2022 OR #LulaVergonhaNacional OR #LulaNao OR #PTOrganizacaoCriminosa OR #BolsonaroPresidente22 OR #ForaBolsonaro) place_country:BR has:geo'\n",
    "\n",
    "# Pull tweets from september \n",
    "start = datetime.datetime(2022,9,1)\n",
    "end = datetime.datetime(2022,9,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#City lists for each state\n",
    "AClist = ufbr.list_cidades('AC')\n",
    "ALlist = ufbr.list_cidades('AL')\n",
    "AMlist = ufbr.list_cidades('AM')\n",
    "APlist = ufbr.list_cidades('AP')\n",
    "BAlist = ufbr.list_cidades('BA')\n",
    "CElist = ufbr.list_cidades('CE')\n",
    "DFlist = ufbr.list_cidades('DF')\n",
    "ESlist = ufbr.list_cidades('ES')\n",
    "GOlist = ufbr.list_cidades('GO')\n",
    "MAlist = ufbr.list_cidades('MA')\n",
    "MGlist = ufbr.list_cidades('MG')\n",
    "MSlist = ufbr.list_cidades('MS')\n",
    "MTlist = ufbr.list_cidades('MT')\n",
    "PAlist = ufbr.list_cidades('PA')\n",
    "PBlist = ufbr.list_cidades('PB')\n",
    "PElist = ufbr.list_cidades('PE')\n",
    "PIlist = ufbr.list_cidades('PI')\n",
    "PRlist = ufbr.list_cidades('PR')\n",
    "RJlist = ufbr.list_cidades('RJ')\n",
    "RNlist = ufbr.list_cidades('RN')\n",
    "ROlist = ufbr.list_cidades('RO')\n",
    "RRlist = ufbr.list_cidades('RR')\n",
    "RSlist = ufbr.list_cidades('RS')\n",
    "SClist = ufbr.list_cidades('SC')\n",
    "SElist = ufbr.list_cidades('SE')\n",
    "SPlist = ufbr.list_cidades('SP')\n",
    "TOlist = ufbr.list_cidades('TO')\n",
    "\n",
    "#Toxicity lists for each state\n",
    "AC = []\n",
    "AL = []\n",
    "AM = []\n",
    "AP = []\n",
    "BA = []\n",
    "CE = []\n",
    "DF = []\n",
    "ES = []\n",
    "GO = []\n",
    "MA = []\n",
    "MG = []\n",
    "MS = []\n",
    "MT = []\n",
    "PA = []\n",
    "PB = []\n",
    "PE = []\n",
    "PI = []\n",
    "PR = []\n",
    "RJ = []\n",
    "RN = []\n",
    "RO = []\n",
    "RR = []\n",
    "RS = []\n",
    "SC = []\n",
    "SE = []\n",
    "SP = []\n",
    "TO = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdc535",
   "metadata": {},
   "source": [
    "### Collect 5.000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5d83d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pages \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mPaginator(\u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39msearch_all_tweets,\n\u001b[0;32m      2\u001b[0m                           start_time\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m      3\u001b[0m                           end_time\u001b[38;5;241m=\u001b[39mend, \n\u001b[0;32m      4\u001b[0m                           query\u001b[38;5;241m=\u001b[39mquery, \n\u001b[0;32m      5\u001b[0m                           max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m      6\u001b[0m                           expansions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo.place_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      7\u001b[0m                           tweet_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_annotations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m                           place_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplace_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m                           limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "pages = tweepy.Paginator(client.search_all_tweets,\n",
    "                          start_time=start,\n",
    "                          end_time=end, \n",
    "                          query=query, \n",
    "                          max_results=100, \n",
    "                          expansions=['geo.place_id'],\n",
    "                          tweet_fields=['context_annotations', 'created_at', 'geo'],\n",
    "                          place_fields=['geo','place_type','name'],\n",
    "                          limit = 50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f6a09",
   "metadata": {},
   "source": [
    "## Toxicity Function\n",
    "### Input: Tweet text\n",
    "### Output: Toxicity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4605a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseToxicity(tweetText) -> float:\n",
    "    try:\n",
    "        lemmas = nlp(tweetText)\n",
    "        lemmas = ' '.join([x.lemma_ for x in lemmas])\n",
    "        analyze_request = {\n",
    "                'comment': {'text': lemmas},\n",
    "                'requestedAttributes': {'TOXICITY': {}}\n",
    "            }\n",
    "        response = clientPerspective.comments().analyze(body=analyze_request).execute()\n",
    "        return response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "    except Exception as err: \n",
    "        # if the text is recognized as a different language\n",
    "        print(err)\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37141c8d",
   "metadata": {},
   "source": [
    "## Add tweets' toxicities to state list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ffcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = {}\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "## Iterating through Tweets\n",
    "\n",
    "\n",
    "num = 0\n",
    "\n",
    "for page in pages:\n",
    "# Get list of places from includes object\n",
    "    places = places | {place[\"id\"]: place.name for place in page.includes['places']}\n",
    "    \n",
    "    for tweet in page.data:\n",
    "        if places[tweet.geo['place_id']]:\n",
    "            num = num + 1\n",
    "            print(num)\n",
    "            \n",
    "            place = places[tweet.geo['place_id']]\n",
    "            placeNormal = place \n",
    "            place = place.upper()\n",
    "            \n",
    "            tweet = tweet.text\n",
    "            \n",
    "            if place in AClist:\n",
    "                AC.append(analyseToxicity(tweet))\n",
    "            elif place in ALlist:\n",
    "                AL.append(analyseToxicity(tweet))\n",
    "            elif place in AMlist:\n",
    "                AM.append(analyseToxicity(tweet))\n",
    "            elif place in APlist:\n",
    "                AP.append(analyseToxicity(tweet))\n",
    "            elif place in BAlist:\n",
    "                BA.append(analyseToxicity(tweet))\n",
    "            elif place in CElist:\n",
    "                CE.append(analyseToxicity(tweet))\n",
    "            elif placeNormal in DFlist:\n",
    "                DF.append(analyseToxicity(tweet))\n",
    "            elif place in ESlist:\n",
    "                ES.append(analyseToxicity(tweet))\n",
    "            elif place in GOlist:\n",
    "                GO.append(analyseToxicity(tweet))\n",
    "            elif place in MAlist:\n",
    "                MA.append(analyseToxicity(tweet))\n",
    "            elif place in MGlist:\n",
    "                MG.append(analyseToxicity(tweet))\n",
    "            elif place in MSlist:\n",
    "                MS.append(analyseToxicity(tweet))\n",
    "            elif place in MTlist:\n",
    "                MT.append(analyseToxicity(tweet))\n",
    "            elif place in PAlist:\n",
    "                PA.append(analyseToxicity(tweet))\n",
    "            elif place in PBlist:\n",
    "                PB.append(analyseToxicity(tweet))\n",
    "            elif place in PElist:\n",
    "                PE.append(analyseToxicity(tweet))\n",
    "            elif place in PIlist:\n",
    "                PI.append(analyseToxicity(tweet))\n",
    "            elif place in PRlist:\n",
    "                PR.append(analyseToxicity(tweet))\n",
    "            elif place in RJlist:\n",
    "                RJ.append(analyseToxicity(tweet))\n",
    "            elif place in RNlist:\n",
    "                RN.append(analyseToxicity(tweet))\n",
    "            elif place in ROlist:\n",
    "                RO.append(analyseToxicity(tweet))\n",
    "            elif place in RRlist:\n",
    "                RR.append(analyseToxicity(tweet))\n",
    "            elif place in RSlist:\n",
    "                RS.append(analyseToxicity(tweet))\n",
    "            elif place in SClist:\n",
    "                SC.append(analyseToxicity(tweet))\n",
    "            elif place in SElist:\n",
    "                SE.append(analyseToxicity(tweet))\n",
    "            elif place in SPlist:\n",
    "                SP.append(analyseToxicity(tweet))\n",
    "            elif place in TOlist:\n",
    "                TO.append(analyseToxicity(tweet)) \n",
    "                \n",
    "                \n",
    "            time.sleep(1.05) \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba68b4",
   "metadata": {},
   "source": [
    "## Function to calculate average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c46637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst):\n",
    "    if(len(lst) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(lst) / len(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print averages then full lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8253e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AC:\")\n",
    "print(average(AC))\n",
    "print()\n",
    "print(\"AL:\")\n",
    "print(average(AL))\n",
    "print()\n",
    "print(\"AM:\")\n",
    "print(average(AM))\n",
    "print()\n",
    "print(\"AP:\")\n",
    "print(average(AP))\n",
    "print()\n",
    "print(\"BA:\")\n",
    "print(average(BA))\n",
    "print()\n",
    "print(\"CE:\")\n",
    "print(average(CE))\n",
    "print()\n",
    "print(\"DF:\")\n",
    "print(average(DF))\n",
    "print()\n",
    "print(\"ES:\")\n",
    "print(average(ES))\n",
    "print()\n",
    "print(\"GO:\")\n",
    "print(average(GO))\n",
    "print()\n",
    "print(\"MA:\")\n",
    "print(average(MA))\n",
    "print()\n",
    "print(\"MG:\")\n",
    "print(average(MG))\n",
    "print()\n",
    "print(\"MS:\")\n",
    "print(average(MS))\n",
    "print()\n",
    "print(\"MT:\")\n",
    "print(average(MT))\n",
    "print()\n",
    "print(\"PA:\")\n",
    "print(average(PA))\n",
    "print()\n",
    "print(\"PB:\")\n",
    "print(average(PB))\n",
    "print()\n",
    "print(\"PE:\")\n",
    "print(average(PE))\n",
    "print()\n",
    "print(\"PI:\")\n",
    "print(average(PI))\n",
    "print()\n",
    "print(\"PR:\")\n",
    "print(average(PR))\n",
    "print()\n",
    "print(\"RJ:\")\n",
    "print(average(RJ))\n",
    "print()\n",
    "print(\"RN:\")\n",
    "print(average(RN))\n",
    "print()\n",
    "print(\"RO:\")\n",
    "print(average(RO))\n",
    "print()\n",
    "print(\"RR:\")\n",
    "print(average(RR))\n",
    "print()\n",
    "print(\"RS:\")\n",
    "print(average(RS))\n",
    "print()\n",
    "print(\"SC:\")\n",
    "print(average(SC))\n",
    "print()\n",
    "print(\"SE:\")\n",
    "print(average(SE))\n",
    "print()\n",
    "print(\"SP:\")\n",
    "print(average(SP))\n",
    "print()\n",
    "print(\"TO:\")\n",
    "print(average(TO))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AC:\")\n",
    "print(AC)\n",
    "print()\n",
    "print(\"AL:\")\n",
    "print(AL)\n",
    "print()\n",
    "print(\"AM:\")\n",
    "print(AM)\n",
    "print()\n",
    "print(\"AP:\")\n",
    "print(AP)\n",
    "print()\n",
    "print(\"BA:\")\n",
    "print(BA)\n",
    "print()\n",
    "print(\"CE:\")\n",
    "print(CE)\n",
    "print()\n",
    "print(\"DF:\")\n",
    "print(DF)\n",
    "print()\n",
    "print(\"ES:\")\n",
    "print(ES)\n",
    "print()\n",
    "print(\"GO:\")\n",
    "print(GO)\n",
    "print()\n",
    "print(\"MA:\")\n",
    "print(MA)\n",
    "print()\n",
    "print(\"MG:\")\n",
    "print(MG)\n",
    "print()\n",
    "print(\"MS:\")\n",
    "print(MS)\n",
    "print()\n",
    "print(\"MT:\")\n",
    "print(MT)\n",
    "print()\n",
    "print(\"PA:\")\n",
    "print(PA)\n",
    "print()\n",
    "print(\"PB:\")\n",
    "print(PB)\n",
    "print()\n",
    "print(\"PE:\")\n",
    "print(PE)\n",
    "print()\n",
    "print(\"PI:\")\n",
    "print(PI)\n",
    "print()\n",
    "print(\"PR:\")\n",
    "print(PR)\n",
    "print()\n",
    "print(\"RJ:\")\n",
    "print(RJ)\n",
    "print()\n",
    "print(\"RN:\")\n",
    "print(RN)\n",
    "print()\n",
    "print(\"RO:\")\n",
    "print(RO)\n",
    "print()\n",
    "print(\"RR:\")\n",
    "print(RR)\n",
    "print()\n",
    "print(\"RS:\")\n",
    "print(RS)\n",
    "print()\n",
    "print(\"SC:\")\n",
    "print(SC)\n",
    "print()\n",
    "print(\"SE:\")\n",
    "print(SE)\n",
    "print()\n",
    "print(\"SP:\")\n",
    "print(SP)\n",
    "print()\n",
    "print(\"TO:\")\n",
    "print(TO)\n",
    "print()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ee31c",
   "metadata": {},
   "source": [
    "## Add list with toxicities to dict entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "    'AC': AC,\n",
    "    'AL': AL,\n",
    "    'AP': AP,\n",
    "    'AM': AM,\n",
    "    'BA': BA,\n",
    "    'CE': CE,\n",
    "    'DF': DF,\n",
    "    'ES': ES,\n",
    "    'GO': GO,\n",
    "    'MA': MA,\n",
    "    'MT': MT,\n",
    "    'MS': MS,\n",
    "    'MG': MG,\n",
    "    'PA': PA,\n",
    "    'PB': PB,\n",
    "    'PR': PR,\n",
    "    'PE': PE,\n",
    "    'PI': PI,\n",
    "    'RJ': RJ,\n",
    "    'RN': RN,\n",
    "    'RS': RS,\n",
    "    'RO': RO,\n",
    "    'RR': RR,\n",
    "    'SC': SC,\n",
    "    'SP': SP,\n",
    "    'SE': SE,\n",
    "    'TO': TO\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038e866",
   "metadata": {},
   "source": [
    "## Add dict to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ff096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'w') as json_file:\n",
    "    json.dump(states, json_file)\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4cff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
