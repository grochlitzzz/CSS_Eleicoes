# Computational Social Science
### Imports

import time
import keyring
import pandas as pd
import tweepy
from googleapiclient import discovery

## Twitter API Access
### Secure access with keyring library (not crucial)

APIKey = keyring.get_password("twitter", "api_key")
APIKeySecret = keyring.get_password("twitter", "api_key_secret")
BearerToken = keyring.get_password("twitter", "bearer_Token")
TOKEN = keyring.get_password("twitter", "token")
TOKEN_SECRET = keyring.get_password("twitter", "token_secret")

## Accessing Twitter API

auth = tweepy.OAuthHandler(APIKey, APIKeySecret)
auth.set_access_token(TOKEN, TOKEN_SECRET)
api = tweepy.API(auth)
client = tweepy.Client(bearer_token=BearerToken)

## Sentiment Analysis
### Perspective API access

API_Perspective = "AIzaSyCyl26ferU06eSf6yPWHcmYz1U5IUWQI6M"
clientPerspective = discovery.build(
    "commentanalyzer",
    "vlaphal",
    developerKey=API_Perspective,
    discoveryServiceUrl="https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1",
    static_discovery=False,
)

## Getting Tweets
import datetime

query = "#politica #eleicoes place_country:BR -is:retweet has:geo"
start = datetime.datetime(2022,7,1)
end = datetime.datetime(2022,10,30)

res = client.search_all_tweets(start_time=start,end_time=end, query=query, max_results=100, expansions=["geo.place_id"])
places = {u['id']:u for u in res.includes["places"]}
print(res)

## Iterating through Tweets
import spacy

nlp = spacy.load('pt_core_news_sm')
sentences_lemmas = []
geoLocationList = []

for tweet in res.data:
    if places[tweet.geo["place_id"]] is not None:
        place = places[tweet.geo["place_id"]]
        lemmas = nlp(tweet.text)
        lemmas = ' '.join([x.lemma_ for x in lemmas])
        sentences_lemmas.append(lemmas)
        geoLocationList.append(place)
print(geoLocationList)

## Creating DataFrame
result = pd.DataFrame()

## Applying Sentiment Analysis / Measuring Toxicity
for index, lemma in enumerate(sentences_lemmas):
    time.sleep(2.1)
    analyze_request = {
            'comment': {'text': lemma},
            'requestedAttributes': {'TOXICITY': {}}
        }
    response = clientPerspective.comments().analyze(body=analyze_request).execute()
    temp = {"Text": lemma, "Toxicity Score": response['attributeScores']['TOXICITY']['summaryScore']['value'], "Place": geoLocationList[index].full_name}
    result = pd.concat([result, pd.DataFrame([temp])], ignore_index=True)
result.to_json("C:\\Users\\vinia\\PycharmProjects\\CSS\\dataWithDate.json")
print(result)
