{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Jupyter-Notebook. You can either simply read the PDF, or open the notebook with Jupyter to run the code yourself. If you have not yet installed Jupyter Notebooks, the easiest way is to install [Anaconda](https://www.anaconda.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, you can start the notebook by opening a Notebook via `jupyter notebook` in your terminal and navigating to the appropriate folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.\" [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss two different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Based Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple approach is to compile a list of indicative words for each sentiment to be classified. While this method is robust and explainable, it can be hard to bootstrap by hand.\n",
    "\n",
    "Many libraries exist, providing precompiled lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Computational Social Sciences is super exciting.\",\n",
    "    \"Working on projects are very boring.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = [ \"good\", \"awesome\", \"exciting\" ]\n",
    "negative_words = [ \"boring\", \"bad\", \"no fun\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "NR_SENTIMENTS = 2\n",
    "\n",
    "counts = np.zeros((len(sentences), NR_SENTIMENTS), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(sentences):\n",
    "    for word in positive_words:\n",
    "        if word in sentence:\n",
    "            counts[idx, 0] += 1\n",
    "        \n",
    "    for word in negative_words:\n",
    "        if word in sentence:\n",
    "            counts[idx, 1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Computational Social Sciences is super exciting.\" contains 1 positive and 0 negative words.\n",
      "\"Working on projects are very boring.\" contains 0 positive and 1 negative words.\n",
      "\"Computational Social Sciences is super exciting.\" contains 1 positive and 0 negative words.\n",
      "\"Working on projects are very boring.\" contains 0 positive and 1 negative words.\n"
     ]
    }
   ],
   "source": [
    "for count, sentence in zip(counts, sentences):\n",
    "    print(f\"\\\"{sentence}\\\" contains {count[0]} positive and {count[1]} negative words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially for German, but also for English texts, you will want to perform stemming before counting keywords. [Spacy](https://spacy.io/models/en) is a good library to do this.\n",
    "After installing Spacy, you will need to choose a [model](https://spacy.io/models/en) and download it with\n",
    "\n",
    "`python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gcroc\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.4.1) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\gcroc\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.4.1) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Computational Social Sciences is super exciting.\" turns into \"Computational Social Sciences be super exciting .\"\n",
      "\"Working on projects are very boring.\" turns into \"work on project be very boring .\"\n",
      "\"Computational Social Sciences is super exciting.\" turns into \"Computational Social Sciences be super exciting .\"\n",
      "\"Working on projects are very boring.\" turns into \"work on project be very boring .\"\n"
     ]
    }
   ],
   "source": [
    "sentences_lemmas = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    lemmas = nlp(sentence)\n",
    "    lemmas = ' '.join([x.lemma_ for x in lemmas]) \n",
    "    sentences_lemmas.append(lemmas)\n",
    "    \n",
    "for sent, lemma in zip(sentences, sentences_lemmas):\n",
    "    print(f\"\\\"{sent}\\\" turns into \\\"{lemma}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep-Learning Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have installed [Huggingface](https://huggingface.co/docs/transformers/installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the [Models-Section](https://huggingface.co/models) to search for a pretrained Model that fits your needs.\n",
    "Make sure to look for models that fit your language and target sentiments. You should also have a look on the data which the model was trained on. The closer this data matches your own, the more likely the model will produce reasonable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download your model and package it into a pipeline in a single command.\n",
    "This might take a while the first time you execute this command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs vastly accelerate the inference process. If you have a recent NVidia GPU at hand, you can add `device = 0`. \n",
    "If you don't, you can set `device = -1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\", device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to load your data into memory and clean it up as far as possible. If you get poor results, you can try to remove emojis, double punctuation, and so on. Also, check if your model is called `cased`, in which case it differentiates between `Trump` and `trump`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting your Texts into Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models can only handle individual sentences (easily). You hence need to split your texts into single sentences. After splitting and classifying, you will need to come up with a good way to recombine those sentences, e.g., by taking the average of all sentences, or looking at the data passage by passage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A suitable, easy package to do this is [Sentence Splitter](https://github.com/mediacloud/sentence-splitter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a paragraph.\n",
      "It contains several sentences.\n",
      "\"But why,\" you ask?\n",
      "This is a paragraph.\n",
      "It contains several sentences.\n",
      "\"But why,\" you ask?\n"
     ]
    }
   ],
   "source": [
    "from sentence_splitter import split_text_into_sentences\n",
    "sentences = split_text_into_sentences(\n",
    "    text='This is a paragraph. It contains several sentences. \"But why,\" you ask?',\n",
    "    language='en'\n",
    ")\n",
    "\n",
    "for sent in sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying your Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will use some sample sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Computational Social Sciences is super exciting.\",\n",
    "    \"Working on projects can be really boring.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Computational Social Sciences is super exciting.\" is classified as POSITIVE with confidence 0.9985401630401611\n",
      "\"Working on projects can be really boring.\" is classified as NEGATIVE with confidence 0.9992350339889526\n",
      "\"Computational Social Sciences is super exciting.\" is classified as POSITIVE with confidence 0.9985401630401611\n",
      "\"Working on projects can be really boring.\" is classified as NEGATIVE with confidence 0.9992350339889526\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_analysis(sentences)\n",
    "\n",
    "for score, sent in zip(scores, sentences):\n",
    "    print(f\"\\\"{sent}\\\"\", 'is classified as', score['label'], \"with confidence\", score['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more than 10 sentences, you should split the data into multiple batches. You can also iterate over each sentence individually in that case. `tqdm` is a very good package to monitor your progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 2/2 [00:00<00:00,  4.23it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "\n",
    "for sent in tqdm(sentences, ncols=50):\n",
    "    score = sentiment_analysis([ sent ])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Footnotes\n",
    "[1] [Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert anything to text before working with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/striprtf/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data - even if not all of it, show that you can get it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
