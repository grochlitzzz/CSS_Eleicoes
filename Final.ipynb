{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93baa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational Social Science\n",
    "### Imports\n",
    "\n",
    "import time\n",
    "import keyring\n",
    "import tweepy\n",
    "import datetime\n",
    "import time\n",
    "import spacy\n",
    "from googleapiclient import discovery\n",
    "from pyUFbr.baseuf import ufbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a269a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Twitter API Access\n",
    "### Secure access with keyring library (not crucial)\n",
    "\n",
    "APIKey = \"otyOoFqTqYG2S5BExsnu4Mu9E\"\n",
    "APIKeySecret = \"4OXZSaK1SVeXEvHDy8JPsKm3yXOONwKNDPCwv1uyuhmljEBVoO\"\n",
    "BearerToken = \"AAAAAAAAAAAAAAAAAAAAACAnkAEAAAAAkxcXL6XD2TRW9FeYBOiZcxsASkU%3DaVO7yShAWO1KwrZossbSR4OZGyrmWDap4jlnLcNdHSL2IKgKzX\"\n",
    "TOKEN = \"1598267162338131968-HesHQlS0MjKKutBMVE6tv0GMGf9ztU\"\n",
    "TOKEN_SECRET = \"BTvRyVD7Wv1gHbIr3EbZlO1tZcOnooazhs1C9GZiE9lIq\"\n",
    "\n",
    "## Accessing Twitter API\n",
    "\n",
    "auth = tweepy.OAuthHandler(APIKey, APIKeySecret)\n",
    "auth.set_access_token(TOKEN, TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "client = tweepy.Client(bearer_token=BearerToken,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6695d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Analysis\n",
    "### Perspective API access\n",
    "\n",
    "API_Perspective = \"AIzaSyCyl26ferU06eSf6yPWHcmYz1U5IUWQI6M\"\n",
    "clientPerspective = discovery.build(\n",
    "    \"commentanalyzer\",\n",
    "    \"vlaphal\",\n",
    "    developerKey=API_Perspective,\n",
    "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "    static_discovery=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc84c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting Tweets\n",
    "import datetime\n",
    "\n",
    "query = '(#Eleicoes2022 OR #Eleicao2022 OR #Bolsonaro22 OR #LulaPresidente13 OR #lulapresidente2022 OR #LulaPresidente2022 OR #LulaVergonhaNacional OR #LulaNao OR #PTOrganizacaoCriminosa OR #BolsonaroPresidente22 OR #ForaBolsonaro) place_country:BR has:geo'\n",
    "\n",
    "# Pull tweets from july until end of october \n",
    "start = datetime.datetime(2022,7,1)\n",
    "end = datetime.datetime(2022,10,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743b8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#City lists for each state\n",
    "AClist = ufbr.list_cidades('AC')\n",
    "ALlist = ufbr.list_cidades('AL')\n",
    "AMlist = ufbr.list_cidades('AM')\n",
    "APlist = ufbr.list_cidades('AP')\n",
    "BAlist = ufbr.list_cidades('BA')\n",
    "CElist = ufbr.list_cidades('CE')\n",
    "DFlist = ufbr.list_cidades('DF')\n",
    "ESlist = ufbr.list_cidades('ES')\n",
    "GOlist = ufbr.list_cidades('GO')\n",
    "MAlist = ufbr.list_cidades('MA')\n",
    "MGlist = ufbr.list_cidades('MG')\n",
    "MSlist = ufbr.list_cidades('MS')\n",
    "MTlist = ufbr.list_cidades('MT')\n",
    "PAlist = ufbr.list_cidades('PA')\n",
    "PBlist = ufbr.list_cidades('PB')\n",
    "PElist = ufbr.list_cidades('PE')\n",
    "PIlist = ufbr.list_cidades('PI')\n",
    "PRlist = ufbr.list_cidades('PR')\n",
    "RJlist = ufbr.list_cidades('RJ')\n",
    "RNlist = ufbr.list_cidades('RN')\n",
    "ROlist = ufbr.list_cidades('RO')\n",
    "RRlist = ufbr.list_cidades('RR')\n",
    "RSlist = ufbr.list_cidades('RS')\n",
    "SClist = ufbr.list_cidades('SC')\n",
    "SElist = ufbr.list_cidades('SE')\n",
    "SPlist = ufbr.list_cidades('SP')\n",
    "TOlist = ufbr.list_cidades('TO')\n",
    "\n",
    "#Toxicity lists for each state\n",
    "AC = []\n",
    "AL = []\n",
    "AM = []\n",
    "AP = []\n",
    "BA = []\n",
    "CE = []\n",
    "DF = []\n",
    "ES = []\n",
    "GO = []\n",
    "MA = []\n",
    "MG = []\n",
    "MS = []\n",
    "MT = []\n",
    "PA = []\n",
    "PB = []\n",
    "PE = []\n",
    "PI = []\n",
    "PR = []\n",
    "RJ = []\n",
    "RN = []\n",
    "RO = []\n",
    "RR = []\n",
    "RS = []\n",
    "SC = []\n",
    "SE = []\n",
    "SP = []\n",
    "TO = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ae62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = tweepy.Paginator(client.search_all_tweets,\n",
    "                          start_time=start,\n",
    "                          end_time=end, \n",
    "                          query=query, \n",
    "                          max_results=100, \n",
    "                          expansions=['geo.place_id'],\n",
    "                          tweet_fields=['context_annotations', 'created_at', 'geo'],\n",
    "                          place_fields=['geo','place_type','name'],\n",
    "                          limit = 2) # 100.000 tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19540228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseToxicity(tweetText) -> float:\n",
    "    lemmas = nlp(tweetText)\n",
    "    lemmas = ' '.join([x.lemma_ for x in lemmas])\n",
    "    analyze_request = {\n",
    "            'comment': {'text': lemmas},\n",
    "            'requestedAttributes': {'TOXICITY': {}}\n",
    "        }\n",
    "    response = clientPerspective.comments().analyze(body=analyze_request).execute()\n",
    "    return response['attributeScores']['TOXICITY']['summaryScore']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4a2e42",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 429 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyCyl26ferU06eSf6yPWHcmYz1U5IUWQI6M&alt=json returned \"Quota exceeded for quota metric 'Analysis requests (AnalyzeComment)' and limit 'Analysis requests (AnalyzeComment) per minute' of service 'commentanalyzer.googleapis.com' for consumer 'project_number:1095244807233'.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'RATE_LIMIT_EXCEEDED', 'domain': 'googleapis.com', 'metadata': {'quota_location': 'global', 'quota_limit': 'AnalyzeRequestsPerMinutePerProject', 'consumer': 'projects/1095244807233', 'service': 'commentanalyzer.googleapis.com', 'quota_limit_value': '60', 'quota_metric': 'CommentAnalyzerService/analyze_requests'}}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Request a higher quota limit.', 'url': 'https://cloud.google.com/docs/quota#requesting_higher_quota'}]}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m     RS\u001b[38;5;241m.\u001b[39mappend(analyseToxicity(tweet))\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m place \u001b[38;5;129;01min\u001b[39;00m SClist:\n\u001b[1;32m---> 66\u001b[0m     SC\u001b[38;5;241m.\u001b[39mappend(\u001b[43manalyseToxicity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m place \u001b[38;5;129;01min\u001b[39;00m SElist:\n\u001b[0;32m     68\u001b[0m     SE\u001b[38;5;241m.\u001b[39mappend(analyseToxicity(tweet))\n",
      "Cell \u001b[1;32mIn [9], line 8\u001b[0m, in \u001b[0;36manalyseToxicity\u001b[1;34m(tweetText)\u001b[0m\n\u001b[0;32m      3\u001b[0m lemmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([x\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m lemmas])\n\u001b[0;32m      4\u001b[0m analyze_request \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: lemmas},\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequestedAttributes\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOXICITY\u001b[39m\u001b[38;5;124m'\u001b[39m: {}}\n\u001b[0;32m      7\u001b[0m     }\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclientPerspective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyze_request\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributeScores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOXICITY\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummaryScore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m     callback(resp)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 429 when requesting https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=AIzaSyCyl26ferU06eSf6yPWHcmYz1U5IUWQI6M&alt=json returned \"Quota exceeded for quota metric 'Analysis requests (AnalyzeComment)' and limit 'Analysis requests (AnalyzeComment) per minute' of service 'commentanalyzer.googleapis.com' for consumer 'project_number:1095244807233'.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'RATE_LIMIT_EXCEEDED', 'domain': 'googleapis.com', 'metadata': {'quota_location': 'global', 'quota_limit': 'AnalyzeRequestsPerMinutePerProject', 'consumer': 'projects/1095244807233', 'service': 'commentanalyzer.googleapis.com', 'quota_limit_value': '60', 'quota_metric': 'CommentAnalyzerService/analyze_requests'}}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Request a higher quota limit.', 'url': 'https://cloud.google.com/docs/quota#requesting_higher_quota'}]}]\">"
     ]
    }
   ],
   "source": [
    "places = {}\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "## Iterating through Tweets\n",
    "\n",
    "for page in pages:\n",
    "# Get list of places from includes object\n",
    "    places = places | {place[\"id\"]: place.name for place in page.includes['places']}\n",
    "    \n",
    "    for tweet in page.data:\n",
    "        if places[tweet.geo['place_id']]:\n",
    "            \n",
    "            place = places[tweet.geo['place_id']]\n",
    "            placeNormal = place \n",
    "            place = place.upper()\n",
    "            \n",
    "            tweet = tweet.text\n",
    "            \n",
    "            if place in AClist:\n",
    "                AC.append(analyseToxicity(tweet))\n",
    "            elif place in ALlist:\n",
    "                AL.append(analyseToxicity(tweet))\n",
    "            elif place in AMlist:\n",
    "                AM.append(analyseToxicity(tweet))\n",
    "            elif place in APlist:\n",
    "                AP.append(analyseToxicity(tweet))\n",
    "            elif place in BAlist:\n",
    "                BA.append(analyseToxicity(tweet))\n",
    "            elif place in CElist:\n",
    "                CE.append(analyseToxicity(tweet))\n",
    "            elif placeNormal in DFlist:\n",
    "                DF.append(analyseToxicity(tweet))\n",
    "            elif place in ESlist:\n",
    "                ES.append(analyseToxicity(tweet))\n",
    "            elif place in GOlist:\n",
    "                GO.append(analyseToxicity(tweet))\n",
    "            elif place in MAlist:\n",
    "                MA.append(analyseToxicity(tweet))\n",
    "            elif place in MGlist:\n",
    "                MG.append(analyseToxicity(tweet))\n",
    "            elif place in MSlist:\n",
    "                MS.append(analyseToxicity(tweet))\n",
    "            elif place in MTlist:\n",
    "                MT.append(analyseToxicity(tweet))\n",
    "            elif place in PAlist:\n",
    "                PA.append(analyseToxicity(tweet))\n",
    "            elif place in PBlist:\n",
    "                PB.append(analyseToxicity(tweet))\n",
    "            elif place in PElist:\n",
    "                PE.append(analyseToxicity(tweet))\n",
    "            elif place in PIlist:\n",
    "                PI.append(analyseToxicity(tweet))\n",
    "            elif place in PRlist:\n",
    "                PR.append(analyseToxicity(tweet))\n",
    "            elif place in RJlist:\n",
    "                RJ.append(analyseToxicity(tweet))\n",
    "            elif place in RNlist:\n",
    "                RN.append(analyseToxicity(tweet))\n",
    "            elif place in ROlist:\n",
    "                RO.append(analyseToxicity(tweet))\n",
    "            elif place in RRlist:\n",
    "                RR.append(analyseToxicity(tweet))\n",
    "            elif place in RSlist:\n",
    "                RS.append(analyseToxicity(tweet))\n",
    "            elif place in SClist:\n",
    "                SC.append(analyseToxicity(tweet))\n",
    "            elif place in SElist:\n",
    "                SE.append(analyseToxicity(tweet))\n",
    "            elif place in SPlist:\n",
    "                SP.append(analyseToxicity(tweet))\n",
    "            elif place in TOlist:\n",
    "                TO.append(analyseToxicity(tweet)) \n",
    "                \n",
    "                \n",
    "            time.sleep(2) ## find perfect time \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef33de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AC:\")\n",
    "print(AC)\n",
    "print()\n",
    "print(\"AL:\")\n",
    "print(AL)\n",
    "print()\n",
    "print(\"AM:\")\n",
    "print(AM)\n",
    "print()\n",
    "print(\"AP:\")\n",
    "print(AP)\n",
    "print()\n",
    "print(\"BA:\")\n",
    "print(BA)\n",
    "print()\n",
    "print(\"CE:\")\n",
    "print(CE)\n",
    "print()\n",
    "print(\"DF:\")\n",
    "print(DF)\n",
    "print()\n",
    "print(\"ES:\")\n",
    "print(ES)\n",
    "print()\n",
    "print(\"GO:\")\n",
    "print(GO)\n",
    "print()\n",
    "print(\"MA:\")\n",
    "print(MA)\n",
    "print()\n",
    "print(\"MG:\")\n",
    "print(MG)\n",
    "print()\n",
    "print(\"MS:\")\n",
    "print(MS)\n",
    "print()\n",
    "print(\"MT:\")\n",
    "print(MT)\n",
    "print()\n",
    "print(\"PA:\")\n",
    "print(PA)\n",
    "print()\n",
    "print(\"PB:\")\n",
    "print(PB)\n",
    "print()\n",
    "print(\"PE:\")\n",
    "print(PE)\n",
    "print()\n",
    "print(\"PI:\")\n",
    "print(PI)\n",
    "print()\n",
    "print(\"PR:\")\n",
    "print(PR)\n",
    "print()\n",
    "print(\"RJ:\")\n",
    "print(RJ)\n",
    "print()\n",
    "print(\"RN:\")\n",
    "print(RN)\n",
    "print()\n",
    "print(\"RO:\")\n",
    "print(RO)\n",
    "print()\n",
    "print(\"RR:\")\n",
    "print(RR)\n",
    "print()\n",
    "print(\"RS:\")\n",
    "print(RS)\n",
    "print()\n",
    "print(\"SC:\")\n",
    "print(SC)\n",
    "print()\n",
    "print(\"SE:\")\n",
    "print(SE)\n",
    "print()\n",
    "print(\"SP:\")\n",
    "print(SP)\n",
    "print()\n",
    "print(\"TO:\")\n",
    "print(TO)\n",
    "print()\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
